---
title: "Budget Control"
description: "How to configure budgets in Tyk AI Studio?"
sidebarTitle: "Budget Control"
tags: ['AI Studio', 'AI Management', 'Budget Control']
---

Tyk AI Studio provides a Budget Control system to help organizations manage and limit spending on Large Language Model (LLM) usage.

## Purpose

The primary goals of the Budget Control system are:

*   **Prevent Overspending:** Set hard limits on costs associated with LLM API calls.
*   **Cost Allocation:** Track and enforce spending limits at different granularities (e.g., per organization, per specific LLM configuration).
*   **Predictability:** Provide better predictability for monthly AI operational costs.

## Scope & Configuration

Budgets are typically configured by administrators and applied at specific levels:

*   **Organization Level:** A global budget limit for all LLM usage within the organization.
*   **LLM Configuration Level:** A specific budget limit tied to a particular LLM setup (e.g., a dedicated budget for a high-cost `gpt-4` configuration).
*   **(Potentially) Application/User Level:** Granular budgets might be assignable to specific applications or user groups (depending on implementation specifics).

**Configuration Parameters:**

*   **Limit Amount:** The maximum monetary value allowed (e.g., $500).
*   **Currency:** The currency the budget is defined in (e.g., USD).
*   **Time Period:** The reset interval for the budget, typically monthly (e.g., resets on the 1st of each month).
*   **Scope:** Which entity the budget applies to (Organization, specific LLM Configuration ID, etc.).

Administrators configure these budgets via the Tyk AI Studio UI or API.

    <img src="/img/ai-management/budget-config-ui.png" alt="Budget Config UI" />

## Enforcement

Budget enforcement primarily occurs at the **[Proxy & API Gateway](/ai-management/ai-studio/proxy)**:

1.  **Request Received:** The Proxy receives a request destined for an LLM.
2.  **Cost Estimation:** Before forwarding the request, the Proxy might estimate the potential maximum cost (or rely on post-request cost calculation).
3.  **Budget Check:** The Proxy checks the current spending against all applicable budgets (e.g., the specific LLM config budget AND the overall organization budget) for the current time period.
4.  **Allow or Deny:**
    *   If the current spending plus the estimated/actual cost of the request does *not* exceed the limit(s), the request is allowed to proceed.
    *   If the request *would* cause a budget limit to be exceeded, the request is blocked, and an error is returned to the caller.

## Integration with Other Systems

*   **[Analytics & Monitoring](/ai-management/ai-studio/analytics):** The Analytics system provides the cost data used to track spending against budgets. The current spent amount for a budget period is derived from aggregated analytics data.
*   **[Model Pricing](/ai-management/ai-studio/llm-management):** The pricing definitions are essential for the Analytics system to calculate costs accurately, which in turn feeds the Budget Control system.
*   **[Notification System](/ai-management/ai-studio/notifications):** Budgets can be configured to trigger notifications when spending approaches or reaches defined thresholds (e.g., alert admin when 80% of budget is consumed, notify user/admin when budget is exceeded).

## Benefits

*   **Financial Control:** Prevents unexpected high bills from LLM usage.
*   **Resource Management:** Ensures fair distribution of AI resources according to allocated budgets.
*   **Accountability:** Tracks spending against specific configurations or organizational units.

Budget Control is a critical feature for organizations looking to adopt AI technologies responsibly and manage their operational costs effectively.
